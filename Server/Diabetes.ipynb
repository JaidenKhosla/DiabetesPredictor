{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bb2cuLzGmZ9r"
   },
   "outputs": [],
   "source": [
    "#imports for machine learning and parsing\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split # To split our data for fair testing\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression  # The model itself!\n",
    "from sklearn import preprocessing #LabelEncoders\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import math #for ceil\n",
    "import json\n",
    "\n",
    "import pickle\n",
    "from sklearn import datasets\n",
    "#server imports\n",
    "from flask import Flask\n",
    "from flask import request\n",
    "from flask import jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "#for typechecking\n",
    "from typing import Sequence, Union\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SWB6e1KVm2mm"
   },
   "outputs": [],
   "source": [
    "#loading our dataframe\n",
    "diabetes_dataframe = pd.read_csv(\"./datasets/diabetes_prediction_dataset.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lBcNp85VqhaP"
   },
   "outputs": [],
   "source": [
    "#replacements\n",
    "#To convert categorical data into numerical data, I googled it and you use labelencoding.\n",
    "genderEncoder = preprocessing.LabelEncoder()\n",
    "smokingEncoder = preprocessing.LabelEncoder()\n",
    "\n",
    "diabetes_dataframe[\"gender\"] = genderEncoder.fit_transform(diabetes_dataframe[\"gender\"])\n",
    "diabetes_dataframe[\"smoking_history\"] = smokingEncoder.fit_transform(diabetes_dataframe[\"smoking_history\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "o-MnxUgQqyHx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#splitting\n",
    "features = diabetes_dataframe[['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history', 'bmi', 'HbA1c_level', 'blood_glucose_level']]\n",
    "outputs = diabetes_dataframe[['diabetes']].values.ravel()\n",
    "\n",
    "print(outputs)\n",
    "\n",
    "features_train, features_test, outputs_train, outputs_test = train_test_split(features, outputs, test_size=0.1, random_state=1845)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, model: RegressorMixin, transformModel=True):\n",
    "        self.model = model\n",
    "        if transformModel: model.fit(features_train, outputs_train)\n",
    "    \n",
    "    def test(self, model: None, features=features_test, outputs=outputs_test) -> float:\n",
    "        if model is None: model = self.model\n",
    "        return model.score(features, outputs)\n",
    "    \n",
    "    def predict(self, features: Union[Sequence[Sequence[float]], np.ndarray]):\n",
    "        return self.model.predict(features)\n",
    "\n",
    "class LinearModel(Model):\n",
    "    def __init__(self, transformModel=True):\n",
    "        super().__init__(LinearRegression(), transformModel)\n",
    "\n",
    "class LogisticModel(Model):\n",
    "    def __init__(self, transformModel=True):\n",
    "        super().__init__(LogisticRegression(max_iter=1000), transformModel)\n",
    "\n",
    "class RandomForestModel(Model):\n",
    "    def __init__(self, trees: int,transformModel=True):\n",
    "        super().__init__(RandomForestClassifier(n_estimators=trees), transformModel)\n",
    "\n",
    "class PolynomialModel(Model):\n",
    "    def __init__(self, maxDegree: int):\n",
    "        maxModel = None\n",
    "        score = -1\n",
    "        self.poly: PolynomialFeatures = None\n",
    "        for degree in range(1,maxDegree+1):\n",
    "            iterFeatures = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "            polyTrainedFeatures = iterFeatures.fit_transform(features_train)\n",
    "\n",
    "            iterLinear  = LinearModel(transformModel=False)\n",
    "            iterLinear.model.fit(polyTrainedFeatures, outputs_train)\n",
    "    \n",
    "\n",
    "            iterScore = PolynomialModel.test(None,iterFeatures, iterLinear.model)\n",
    "            if iterScore > score:\n",
    "                maxModel = iterLinear\n",
    "                score = iterScore\n",
    "                self.poly = iterFeatures\n",
    "                \n",
    "        super().__init__(maxModel.model, False)\n",
    "\n",
    "    def test(self, polyFeatures: PolynomialFeatures=None, model: LinearRegression=None) -> float:\n",
    "        if model is None: model = self.model\n",
    "        if polyFeatures is None: polyFeatures = self.poly\n",
    "        \n",
    "        return model.score(polyFeatures.transform(features_test), outputs_test)\n",
    "    \n",
    "    def predict(self, features: Union[Sequence[Sequence[float]], np.array]):\n",
    "        return self.model.predict(self.poly.transform(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "O2mzUWY8rN8V"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#model preperation and training\u001b[39;00m\n\u001b[32m      2\u001b[39m models = {\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m\"\u001b[39m: LinearModel(),\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlogistic\u001b[39m\u001b[33m\"\u001b[39m: LogisticModel(\u001b[32m1000\u001b[39m),\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrandomForest\u001b[39m\u001b[33m\"\u001b[39m : \u001b[43mRandomForestModel\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpolynomial\u001b[39m\u001b[33m\"\u001b[39m : PolynomialModel(\u001b[32m5\u001b[39m)\n\u001b[32m      7\u001b[39m }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mRandomForestModel.__init__\u001b[39m\u001b[34m(self, trees, transformModel)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, trees: \u001b[38;5;28mint\u001b[39m,transformModel=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mRandomForestClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformModel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, model, transformModel)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: RegressorMixin, transformModel=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = model\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m transformModel: \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:487\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    476\u001b[39m trees = [\n\u001b[32m    477\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    479\u001b[39m ]\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:189\u001b[39m, in \u001b[36m_parallel_build_trees\u001b[39m\u001b[34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m class_weight == \u001b[33m\"\u001b[39m\u001b[33mbalanced_subsample\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    187\u001b[39m         curr_sample_weight *= compute_sample_weight(\u001b[33m\"\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m\"\u001b[39m, y, indices=indices)\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    197\u001b[39m     tree._fit(\n\u001b[32m    198\u001b[39m         X,\n\u001b[32m    199\u001b[39m         y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    202\u001b[39m         missing_values_in_feature_mask=missing_values_in_feature_mask,\n\u001b[32m    203\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    462\u001b[39m     builder = BestFirstTreeBuilder(\n\u001b[32m    463\u001b[39m         splitter,\n\u001b[32m    464\u001b[39m         min_samples_split,\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m         \u001b[38;5;28mself\u001b[39m.min_impurity_decrease,\n\u001b[32m    470\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_classes_ = \u001b[38;5;28mself\u001b[39m.n_classes_[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#model preperation and training\n",
    "models = {\n",
    "    \"linear\": LinearModel(),\n",
    "    \"logistic\": LogisticModel(1000),\n",
    "    \"randomForest\" : RandomForestModel(500),\n",
    "    \"polynomial\" : PolynomialModel(5)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "\n",
    "    dataframe: pd.DataFrame\n",
    "\n",
    "    def __init__(self, dataframe: pd.DataFrame, model: Model=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self):\n",
    "        return self.model.predict(self.dataframe)\n",
    "    \n",
    "    def predict_proba(self):\n",
    "        if(hasattr(self.model.model, \"predict_proba\")):\n",
    "            return [self.model.model.predict_proba(self.dataframe)[0][1]]\n",
    "        else:\n",
    "            return self.predict()\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_json(unparsed_json: str):\n",
    "        parsed_json = json.loads(unparsed_json)\n",
    "        return Predictor.json_to_frame(parsed_json)\n",
    "    \n",
    "    @staticmethod\n",
    "    def json_to_frame(parsed_json: dict):\n",
    "        return Predictor(pd.DataFrame([parsed_json]))\n",
    "\n",
    "    def convert_binary_values(self):\n",
    "        self.dataframe[\"gender\"] = genderEncoder.transform(self.dataframe[\"gender\"])\n",
    "        self.dataframe[\"smoking_history\"] = smokingEncoder.transform(self.dataframe[\"smoking_history\"])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def add_model(self, model: Model):\n",
    "        self.model = model\n",
    "        return self\n",
    "    \n",
    "\n",
    "\n",
    "# jsonPredict = Predictor.parse_json(\"\"\"{\n",
    "#     \\\"gender\\\" : \\\"Male\\\",\n",
    "#     \\\"age\\\" : 12.0,\n",
    "#     \\\"hypertension\\\": 1,\n",
    "#     \\\"heart_disease\\\": 1,\n",
    "#     \\\"smoking_history\\\": \\\"current\\\",\n",
    "#     \\\"bmi\\\" : 23.86,\n",
    "#     \\\"HbA1c_level\\\": 4.8,\n",
    "#     \\\"blood_glucose_level\\\": 157.0\n",
    "# }\"\"\").convert_binary_values().predict().tolist()\n",
    "\n",
    "# print(jsonPredict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<flask_cors.extension.CORS at 0x701fd25b3b00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Serverside Setup\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#App Route\n",
    "@app.route(\"/generate\", methods=[\"POST\"])\n",
    "def generate():\n",
    "    clientJson = request.json\n",
    "\n",
    "    model = clientJson[\"model\"]\n",
    "    features = clientJson[\"features\"]\n",
    "\n",
    "    if(models.get(model, None) is None):\n",
    "        return jsonify({\"result\": f\"The {model} model doesn't exist.\"})\n",
    "\n",
    "    currModel = Predictor.json_to_frame(features).convert_binary_values().add_model(models[model])\n",
    "\n",
    "    prediction = float(currModel.predict()[0])\n",
    "    probability = float(currModel.predict_proba()[0])\n",
    "\n",
    "    \n",
    "\n",
    "    return jsonify({\"result\": [prediction, probability]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [25/Jun/2025 23:13:49] \"OPTIONS /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:13:49] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:13:57] \"OPTIONS /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:13:57] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:15:00] \"OPTIONS /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:15:00] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:15:03] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:15:14] \"OPTIONS /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:15:14] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:17:22] \"OPTIONS /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:17:22] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:17:40] \"OPTIONS /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:17:41] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:18:00] \"OPTIONS /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:18:00] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:18:29] \"OPTIONS /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:18:29] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:18:30] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:18:32] \"POST /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:21:25] \"OPTIONS /generate HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jun/2025 23:21:25] \"POST /generate HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "#Run\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}